{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import compute_class_weight\n",
    "import keras.backend as K\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_questionmark_count_</th>\n",
       "      <th>_AJD_count_</th>\n",
       "      <th>_ADP_count_</th>\n",
       "      <th>_ADV_count_</th>\n",
       "      <th>_AUX_count_</th>\n",
       "      <th>_CCONJ_count_</th>\n",
       "      <th>_DET_count_</th>\n",
       "      <th>_INTJ_count_</th>\n",
       "      <th>_NOUN_count_</th>\n",
       "      <th>_NUM_count_</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>_label_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.552959</td>\n",
       "      <td>-7.758190</td>\n",
       "      <td>-17.432704</td>\n",
       "      <td>7.485336</td>\n",
       "      <td>-6.116660</td>\n",
       "      <td>5.172562</td>\n",
       "      <td>7.584496</td>\n",
       "      <td>5.250462</td>\n",
       "      <td>-1.320692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.110094</td>\n",
       "      <td>-5.106038</td>\n",
       "      <td>-6.896137</td>\n",
       "      <td>-6.444591</td>\n",
       "      <td>4.211719</td>\n",
       "      <td>10.020246</td>\n",
       "      <td>-0.814034</td>\n",
       "      <td>-3.377685</td>\n",
       "      <td>1.531344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.163507</td>\n",
       "      <td>5.605024</td>\n",
       "      <td>-18.668275</td>\n",
       "      <td>-20.377143</td>\n",
       "      <td>-3.610264</td>\n",
       "      <td>0.414532</td>\n",
       "      <td>-11.114808</td>\n",
       "      <td>-3.477304</td>\n",
       "      <td>-4.977881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.105754</td>\n",
       "      <td>-1.297430</td>\n",
       "      <td>-9.423036</td>\n",
       "      <td>-1.073635</td>\n",
       "      <td>8.888151</td>\n",
       "      <td>6.058524</td>\n",
       "      <td>4.917495</td>\n",
       "      <td>7.490066</td>\n",
       "      <td>-1.712665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.045707</td>\n",
       "      <td>-35.856213</td>\n",
       "      <td>-24.074799</td>\n",
       "      <td>-23.920559</td>\n",
       "      <td>16.694527</td>\n",
       "      <td>10.680893</td>\n",
       "      <td>-16.323111</td>\n",
       "      <td>40.139483</td>\n",
       "      <td>-10.349179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _questionmark_count_  _AJD_count_  _ADP_count_  _ADV_count_  _AUX_count_  \\\n",
       "0                     2            0            7            1            1   \n",
       "1                     2            0            3            3            0   \n",
       "2                     1            0            6            3            0   \n",
       "3                     1            0            2            1            0   \n",
       "4                     1            0           38            6            6   \n",
       "\n",
       "   _CCONJ_count_  _DET_count_  _INTJ_count_  _NOUN_count_  _NUM_count_  ...  \\\n",
       "0              0            3             0            18            2  ...   \n",
       "1              2            5             0            12            2  ...   \n",
       "2              2            6             0            23            1  ...   \n",
       "3              1            2             0            11            1  ...   \n",
       "4              2           31             0            56            3  ...   \n",
       "\n",
       "         491        492        493        494        495        496  \\\n",
       "0   7.552959  -7.758190 -17.432704   7.485336  -6.116660   5.172562   \n",
       "1  -7.110094  -5.106038  -6.896137  -6.444591   4.211719  10.020246   \n",
       "2 -12.163507   5.605024 -18.668275 -20.377143  -3.610264   0.414532   \n",
       "3   2.105754  -1.297430  -9.423036  -1.073635   8.888151   6.058524   \n",
       "4 -19.045707 -35.856213 -24.074799 -23.920559  16.694527  10.680893   \n",
       "\n",
       "         497        498        499  _label_  \n",
       "0   7.584496   5.250462  -1.320692        1  \n",
       "1  -0.814034  -3.377685   1.531344        1  \n",
       "2 -11.114808  -3.477304  -4.977881        1  \n",
       "3   4.917495   7.490066  -1.712665        1  \n",
       "4 -16.323111  40.139483 -10.349179        1  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('data/mails_embedded_doc2vec_bigrams.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no subsampling\n",
    "df = data[data._label_!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 3324, 0: 420})\n"
     ]
    }
   ],
   "source": [
    "shuffler = ShuffleSplit(n_splits=1,test_size=0.3, random_state=42)\n",
    "train_indexes, test_indexes = list(shuffler.split(df.index))[0]\n",
    "y_train = df.iloc[train_indexes,:]._label_\n",
    "df_train = df.iloc[train_indexes,:].drop('_label_', axis = 1)\n",
    "y_test = df.iloc[test_indexes,:]._label_\n",
    "df_test = df.iloc[test_indexes,:].drop('_label_', axis = 1)\n",
    "print(Counter(y_train))\n",
    "\n",
    "df_features_train = df_train.iloc[:,:18] #meta-data\n",
    "df_features_test = df_test.iloc[:,:18]\n",
    "df_embeddings_train = df_train.iloc[:,18:] #word embeddings\n",
    "df_embeddings_test = df_test.iloc[:,18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.457142857142857, 1: 0.5631768953068592}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = compute_class_weight('balanced', classes = [0,1], y = y_train)\n",
    "class_weight = {0:class_weight[0], 1:class_weight[1]}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler = StandardScaler()\n",
    "X_features_train = features_scaler.fit_transform(df_features_train)\n",
    "X_features_test = features_scaler.transform(df_features_test)\n",
    "embedding_scaler = StandardScaler()\n",
    "X_embeddings_train = embedding_scaler.fit_transform(df_embeddings_train)\n",
    "X_embeddings_test = embedding_scaler.transform(df_embeddings_test)\n",
    "\n",
    "X_features_train = np.reshape(X_features_train, (X_features_train.shape[0], 1, X_features_train.shape[1]))\n",
    "X_features_test = np.reshape(X_features_test, (X_features_test.shape[0], 1, X_features_test.shape[1]))\n",
    "X_embeddings_train = np.reshape(X_embeddings_train, (X_embeddings_train.shape[0], 1, X_embeddings_train.shape[1]))\n",
    "X_embeddings_test = np.reshape(X_embeddings_test, (X_embeddings_test.shape[0], 1, X_embeddings_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1(y_true, y_pred):    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = keras.Input(shape=(1,500,))\n",
    "meta_in = keras.Input(shape=(1,18,))\n",
    "lstm1 = layers.LSTM(128, return_sequences=True)(text_in)\n",
    "lstm2 = layers.LSTM(64, return_sequences=True)(lstm1)\n",
    "dense1 = layers.Dense(256,activation='relu')(lstm2)\n",
    "drop = layers.Dropout(0.5)(dense1)\n",
    "merged = layers.concatenate([drop, meta_in])\n",
    "dense2 = layers.Dense(8, activation='relu')(merged)\n",
    "text_class = layers.Dense(1, activation='sigmoid')(dense2)\n",
    "model1 = keras.Model([text_in, meta_in], text_class)\n",
    "\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=[custom_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2642660aa90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "model1.fit([X_embeddings_train, X_features_train], y_train, batch_size=16,\n",
    "    epochs=200, validation_split=0.2, verbose = 0, workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 140   30]\n",
      " [  21 1414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85       170\n",
      "           1       0.98      0.99      0.98      1435\n",
      "\n",
      "    accuracy                           0.97      1605\n",
      "   macro avg       0.92      0.90      0.91      1605\n",
      "weighted avg       0.97      0.97      0.97      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = model1.predict([X_embeddings_test, X_features_test])\n",
    "y_pred = np.array([1*(pred>=0.5) for pred in y_prob])\n",
    "y_pred = y_pred[:,0,0]\n",
    "\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(CM)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = keras.Input(shape=(1,500,))\n",
    "meta_in = keras.Input(shape=(1,18,))\n",
    "conv = layers.Conv1D(filters=32, kernel_size=3, input_shape = (1, 500), padding='same', activation='relu')(text_in)\n",
    "max_pool = layers.MaxPooling1D(pool_size=2, padding = 'same')(conv)\n",
    "lstm1 = layers.LSTM(128, return_sequences=True)(max_pool)\n",
    "lstm2 = layers.LSTM(64, return_sequences=True)(lstm1)\n",
    "dense0 = layers.Dense(256,activation='relu')(lstm2)\n",
    "drop = layers.Dropout(0.5)(dense0)\n",
    "merged = layers.concatenate([drop, meta_in])\n",
    "dense1 = layers.Dense(64, activation='relu')(merged)\n",
    "dense2 = layers.Dense(8, activation='relu')(dense1)\n",
    "text_class = layers.Dense(2, activation='softmax')(dense2)\n",
    "model2 = keras.Model([text_in, meta_in], text_class)\n",
    "\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=[custom_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_probas = to_categorical(y_train)\n",
    "y_train_probas = np.reshape(y_train_probas, (y_train_probas.shape[0], 1, y_train_probas.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b12f0a6c40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([X_embeddings_train, X_features_train], y_train_probas, batch_size=16,\n",
    "    epochs=200, validation_split=0.2, verbose = 0, workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 146   24]\n",
      " [  16 1419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       170\n",
      "           1       0.98      0.99      0.99      1435\n",
      "\n",
      "    accuracy                           0.98      1605\n",
      "   macro avg       0.94      0.92      0.93      1605\n",
      "weighted avg       0.97      0.98      0.97      1605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = model2.predict([X_embeddings_test, X_features_test])\n",
    "y_pred = y_prob.argmax(axis = -1)\n",
    "y_pred[:,0]\n",
    "\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(CM)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNN_LSTM_518features_input_emb_meta\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNN_LSTM_518features_input_emb_meta\\assets\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(features_scaler, 'models/features_scaler')\n",
    "joblib.dump(embedding_scaler, 'models/embedding_scaler')\n",
    "# model1.save('models/LSTM_518features_input_emb_meta')\n",
    "model2.save('models/CNN_LSTM_518features_input_emb_meta')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "444ad55116b32659c86cf21366f06a0b6b15c21184a40d72a1d77ccdcbfe1879"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
