{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams + Word embedding + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import keras.backend as K\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_questionmark_count_</th>\n",
       "      <th>_AJD_count_</th>\n",
       "      <th>_ADP_count_</th>\n",
       "      <th>_ADV_count_</th>\n",
       "      <th>_AUX_count_</th>\n",
       "      <th>_CCONJ_count_</th>\n",
       "      <th>_DET_count_</th>\n",
       "      <th>_INTJ_count_</th>\n",
       "      <th>_NOUN_count_</th>\n",
       "      <th>_NUM_count_</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>_label_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.552959</td>\n",
       "      <td>-7.758190</td>\n",
       "      <td>-17.432704</td>\n",
       "      <td>7.485336</td>\n",
       "      <td>-6.116660</td>\n",
       "      <td>5.172562</td>\n",
       "      <td>7.584496</td>\n",
       "      <td>5.250462</td>\n",
       "      <td>-1.320692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.110094</td>\n",
       "      <td>-5.106038</td>\n",
       "      <td>-6.896137</td>\n",
       "      <td>-6.444591</td>\n",
       "      <td>4.211719</td>\n",
       "      <td>10.020246</td>\n",
       "      <td>-0.814034</td>\n",
       "      <td>-3.377685</td>\n",
       "      <td>1.531344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.163507</td>\n",
       "      <td>5.605024</td>\n",
       "      <td>-18.668275</td>\n",
       "      <td>-20.377143</td>\n",
       "      <td>-3.610264</td>\n",
       "      <td>0.414532</td>\n",
       "      <td>-11.114808</td>\n",
       "      <td>-3.477304</td>\n",
       "      <td>-4.977881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.105754</td>\n",
       "      <td>-1.297430</td>\n",
       "      <td>-9.423036</td>\n",
       "      <td>-1.073635</td>\n",
       "      <td>8.888151</td>\n",
       "      <td>6.058524</td>\n",
       "      <td>4.917495</td>\n",
       "      <td>7.490066</td>\n",
       "      <td>-1.712665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.045707</td>\n",
       "      <td>-35.856213</td>\n",
       "      <td>-24.074799</td>\n",
       "      <td>-23.920559</td>\n",
       "      <td>16.694527</td>\n",
       "      <td>10.680893</td>\n",
       "      <td>-16.323111</td>\n",
       "      <td>40.139483</td>\n",
       "      <td>-10.349179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _questionmark_count_  _AJD_count_  _ADP_count_  _ADV_count_  _AUX_count_  \\\n",
       "0                     2            0            7            1            1   \n",
       "1                     2            0            3            3            0   \n",
       "2                     1            0            6            3            0   \n",
       "3                     1            0            2            1            0   \n",
       "4                     1            0           38            6            6   \n",
       "\n",
       "   _CCONJ_count_  _DET_count_  _INTJ_count_  _NOUN_count_  _NUM_count_  ...  \\\n",
       "0              0            3             0            18            2  ...   \n",
       "1              2            5             0            12            2  ...   \n",
       "2              2            6             0            23            1  ...   \n",
       "3              1            2             0            11            1  ...   \n",
       "4              2           31             0            56            3  ...   \n",
       "\n",
       "         491        492        493        494        495        496  \\\n",
       "0   7.552959  -7.758190 -17.432704   7.485336  -6.116660   5.172562   \n",
       "1  -7.110094  -5.106038  -6.896137  -6.444591   4.211719  10.020246   \n",
       "2 -12.163507   5.605024 -18.668275 -20.377143  -3.610264   0.414532   \n",
       "3   2.105754  -1.297430  -9.423036  -1.073635   8.888151   6.058524   \n",
       "4 -19.045707 -35.856213 -24.074799 -23.920559  16.694527  10.680893   \n",
       "\n",
       "         497        498        499  _label_  \n",
       "0   7.584496   5.250462  -1.320692        1  \n",
       "1  -0.814034  -3.377685   1.531344        1  \n",
       "2 -11.114808  -3.477304  -4.977881        1  \n",
       "3   4.917495   7.490066  -1.712665        1  \n",
       "4 -16.323111  40.139483 -10.349179        1  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('data/mails_embedded_doc2vec_bigrams.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1(y_true, y_pred):    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = data[data._label_==2].drop('_label_', axis = 1)\n",
    "X, y = data[data['_label_'] != 2].drop('_label_', axis = 1), data[data['_label_'] != 2]._label_\n",
    "X, X_test, y, y_test = train_test_split(X.values, y.values, test_size=0.15, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_val)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.3710407239819, 1: 0.5645821157218002}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = compute_class_weight('balanced', classes = [0,1], y = y_train)\n",
    "class_weight = {0:class_weight[0], 1:class_weight[1]}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 128)            331264    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 64)             49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 256)            16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 8)              2056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 1)              9         \n",
      "=================================================================\n",
      "Total params: 399,377\n",
      "Trainable params: 399,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(LSTM(128, input_shape = (1, 518), return_sequences=True))\n",
    "model1.add(LSTM(64, return_sequences=True))\n",
    "model1.add(Dense(256,activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(8,activation='relu'))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=[custom_f1])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "194/194 [==============================] - 5s 9ms/step - loss: 0.3958 - custom_f1: 0.9307 - val_loss: 0.1735 - val_custom_f1: 0.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x186a954b5b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,y_train,batch_size=16,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_custom_f1',min_delta=0.000001)], class_weight=class_weight,\n",
    "          workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 54  10]\n",
      " [ 27 591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.74        64\n",
      "           1       0.98      0.96      0.97       618\n",
      "\n",
      "    accuracy                           0.95       682\n",
      "   macro avg       0.83      0.90      0.86       682\n",
      "weighted avg       0.95      0.95      0.95       682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = model1.predict(X_val)\n",
    "y_pred = np.array([1*(pred>=0.5) for pred in y_prob])\n",
    "y_pred = y_pred[:,0,0]\n",
    "\n",
    "CM = confusion_matrix(y_val, y_pred)\n",
    "print(CM)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1, 32)             49760     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 103,777\n",
      "Trainable params: 103,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv1D(filters=32, kernel_size=3, input_shape = (1, 518), padding='same', activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=2, padding = 'same'))\n",
    "model3.add(LSTM(100))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(8,activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=[custom_f1])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.3710407239819, 1: 0.5645821157218002}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = compute_class_weight('balanced', classes = [0,1], y = y_train)\n",
    "class_weight = {0:class_weight[0], 1:class_weight[1]}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 2s 8ms/step - loss: 0.4807 - custom_f1: 0.9390 - val_loss: 0.2148 - val_custom_f1: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x186b623c190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train,y_train, batch_size = 32,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)], class_weight=class_weight,\n",
    "          workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52  12]\n",
      " [ 37 581]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.81      0.68        64\n",
      "           1       0.98      0.94      0.96       618\n",
      "\n",
      "    accuracy                           0.93       682\n",
      "   macro avg       0.78      0.88      0.82       682\n",
      "weighted avg       0.94      0.93      0.93       682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(X_val)\n",
    "y_pred = np.array([1*(pred>=0.5) for pred in y_pred])\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "CM = confusion_matrix(y_val, y_pred)\n",
    "print(CM)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data[data._label_==0].sample(590, random_state = 42)\n",
    "y1 = x1._label_\n",
    "x1 = x1.drop('_label_', axis = 1)\n",
    "x2 = data[data._label_==1].sample(590, random_state = 42)\n",
    "y2 = x2._label_\n",
    "x2 = x2.drop('_label_', axis = 1)\n",
    "Xt = np.concatenate([x1,x2])\n",
    "yt = np.concatenate([y1, y2])\n",
    "\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(Xt, yt, test_size=0.15, random_state=42)\n",
    "Xt_train, Xt_val,yt_train, yt_val = train_test_split(Xt_train, yt_train, test_size=0.15, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xt_train = scaler.fit_transform(Xt_train)\n",
    "Xt_val = scaler.transform(Xt_val)\n",
    "Xt_test = scaler.transform(Xt_val)\n",
    "Xt_train = np.reshape(Xt_train, (Xt_train.shape[0], 1, Xt_train.shape[1]))\n",
    "Xt_val = np.reshape(Xt_val, (Xt_val.shape[0], 1, Xt_val.shape[1]))\n",
    "Xt_test = np.reshape(Xt_test, (Xt_test.shape[0], 1, Xt_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 128)            331264    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 64)             49408     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1, 256)            16640     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1, 8)              2056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1, 1)              9         \n",
      "=================================================================\n",
      "Total params: 399,377\n",
      "Trainable params: 399,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(LSTM(128, input_shape = (1, 518), return_sequences=True))\n",
    "model1.add(LSTM(64, return_sequences=True))\n",
    "model1.add(Dense(256,activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(8,activation='relu'))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=[custom_f1])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x186b61c9520>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(Xt_train,yt_train,batch_size=16,epochs=100,\n",
    "          validation_split=0.2, verbose = 0, workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  8]\n",
      " [ 6 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        79\n",
      "           1       0.89      0.92      0.90        72\n",
      "\n",
      "    accuracy                           0.91       151\n",
      "   macro avg       0.91      0.91      0.91       151\n",
      "weighted avg       0.91      0.91      0.91       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = model1.predict(Xt_val)\n",
    "y_pred = np.array([1*(pred>=0.5) for pred in y_prob])\n",
    "y_pred = y_pred[:,0,0]\n",
    "\n",
    "CM = confusion_matrix(yt_val, y_pred)\n",
    "print(CM)\n",
    "print(classification_report(yt_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1, 32)             49760     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 103,777\n",
      "Trainable params: 103,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv1D(filters=32, kernel_size=3, input_shape = (1, 518), padding='same', activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=2, padding = 'same'))\n",
    "model3.add(LSTM(100))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(8,activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=[custom_f1])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x186baf85af0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(Xt_train,yt_train, batch_size = 16,epochs=100,\n",
    "          validation_split=0.2,verbose = 0, workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  9]\n",
      " [ 5 67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        79\n",
      "           1       0.88      0.93      0.91        72\n",
      "\n",
      "    accuracy                           0.91       151\n",
      "   macro avg       0.91      0.91      0.91       151\n",
      "weighted avg       0.91      0.91      0.91       151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(Xt_val)\n",
    "y_pred = np.array([1*(pred>=0.5) for pred in y_pred])\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "CM = confusion_matrix(yt_val, y_pred)\n",
    "print(CM)\n",
    "print(classification_report(yt_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, input_shape = (1, 518), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding = 'same'))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', custom_f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165855901955509"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "nn_model = KerasClassifier(build_fn=create_model, epochs = 15, batch_size = 32, verbose = 0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(nn_model, Xt_train, yt_train, cv=kfold, scoring = 'f1', verbose = 0)\n",
    "\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "444ad55116b32659c86cf21366f06a0b6b15c21184a40d72a1d77ccdcbfe1879"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
