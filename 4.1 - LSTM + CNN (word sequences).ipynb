{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import keras.backend as K\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data/mails_preprocessing.json').drop('from', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>_questionmark_count_</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>_AJD_count_</th>\n",
       "      <th>_ADP_count_</th>\n",
       "      <th>_ADV_count_</th>\n",
       "      <th>_AUX_count_</th>\n",
       "      <th>_CCONJ_count_</th>\n",
       "      <th>_DET_count_</th>\n",
       "      <th>...</th>\n",
       "      <th>_NOUN_count_</th>\n",
       "      <th>_NUM_count_</th>\n",
       "      <th>_PRON_count_</th>\n",
       "      <th>_PROPN_count_</th>\n",
       "      <th>_PUNCT_count_</th>\n",
       "      <th>_SCONJ_count_</th>\n",
       "      <th>_SYM_count_</th>\n",
       "      <th>_VERB_count_</th>\n",
       "      <th>_X_count_</th>\n",
       "      <th>unique_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>acces decibel bonjour pouvez vous donner les a...</td>\n",
       "      <td>2</td>\n",
       "      <td>acce decibel bonjour pouvoir donner acces deci...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>actes indemnités hospitalières tu sais ce que ...</td>\n",
       "      <td>2</td>\n",
       "      <td>acte indemnite hospitalier savoir acte frais r...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>analyse des obsèques naissances appareils audi...</td>\n",
       "      <td>1</td>\n",
       "      <td>analyse obseque naissance appareil auditif bon...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ano ihm bonjour j ai un multivalue filtres eta...</td>\n",
       "      <td>1</td>\n",
       "      <td>ano ihm bonjour multivalu filtre etablissement...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ano alimentation réseau sur dcb bonjour je m i...</td>\n",
       "      <td>1</td>\n",
       "      <td>ano alimentation reseau dob bonjour metre inte...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  acces decibel bonjour pouvez vous donner les a...   \n",
       "1      1  actes indemnités hospitalières tu sais ce que ...   \n",
       "2      1  analyse des obsèques naissances appareils audi...   \n",
       "3      1  ano ihm bonjour j ai un multivalue filtres eta...   \n",
       "4      1  ano alimentation réseau sur dcb bonjour je m i...   \n",
       "\n",
       "   _questionmark_count_                                           text_lem  \\\n",
       "0                     2  acce decibel bonjour pouvoir donner acces deci...   \n",
       "1                     2  acte indemnite hospitalier savoir acte frais r...   \n",
       "2                     1  analyse obseque naissance appareil auditif bon...   \n",
       "3                     1  ano ihm bonjour multivalu filtre etablissement...   \n",
       "4                     1  ano alimentation reseau dob bonjour metre inte...   \n",
       "\n",
       "   _AJD_count_  _ADP_count_  _ADV_count_  _AUX_count_  _CCONJ_count_  \\\n",
       "0            0            7            1            1              0   \n",
       "1            0            3            3            0              2   \n",
       "2            0            6            3            0              2   \n",
       "3            0            2            1            0              1   \n",
       "4            0           38            6            6              2   \n",
       "\n",
       "   _DET_count_  ...  _NOUN_count_  _NUM_count_  _PRON_count_  _PROPN_count_  \\\n",
       "0            3  ...            18            2             3              0   \n",
       "1            5  ...            12            2             5              0   \n",
       "2            6  ...            23            1             8              0   \n",
       "3            2  ...            11            1             1              0   \n",
       "4           31  ...            56            3            14              1   \n",
       "\n",
       "   _PUNCT_count_  _SCONJ_count_  _SYM_count_  _VERB_count_  _X_count_  \\\n",
       "0              2              0            0             3          1   \n",
       "1              2              1            0             6          0   \n",
       "2              4              3            0             8          0   \n",
       "3              1              0            0             2          3   \n",
       "4             10              1            0            20          0   \n",
       "\n",
       "   unique_words_count  \n",
       "0                 233  \n",
       "1                 177  \n",
       "2                 274  \n",
       "3                 172  \n",
       "4                 659  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[data['label']!=2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM on word sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1(y_true, y_pred):    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text_lem, df.label, test_size=0.15, stratify=df.label, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train.values, y_train.values, test_size=0.15, stratify=y_train.values, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 3000\n",
    "max_len = 200\n",
    "embedding_dim = 400\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix_tfidf = tok.sequences_to_matrix(sequences, mode = 'tfidf')\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.535211267605634, 1: 0.5619546247818499}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = compute_class_weight('balanced', classes = [0,1], y = y_train)\n",
    "class_weight = {0:class_weight[0], 1:class_weight[1]}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 400)          1200000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 200, 32)           38432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,291,733\n",
      "Trainable params: 1,291,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words,embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[custom_f1])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.535211267605634, 1: 0.5619546247818499}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = compute_class_weight('balanced', classes = [0,1], y = y_train)\n",
    "class_weight = {0:class_weight[0], 1:class_weight[1]}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 6s 369ms/step - loss: 0.6349 - custom_f1: 0.8696 - val_loss: 0.2947 - val_custom_f1: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161858ea400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,y_train,batch_size=256,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_custom_f1',min_delta=0.00001)], class_weight=class_weight,\n",
    "          workers = 6, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_val)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 23ms/step - loss: 0.2999 - custom_f1: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2999166250228882, 0.9694898128509521]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_sequences_matrix, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.63      0.71        75\n",
      "           1       0.96      0.98      0.97       607\n",
      "\n",
      "    accuracy                           0.94       682\n",
      "   macro avg       0.89      0.81      0.84       682\n",
      "weighted avg       0.94      0.94      0.94       682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_sequences_matrix)\n",
    "y_pred = [1*(pred>=0.5) for pred in y_pred]\n",
    "print(classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be392ad8cc747733db05bb7a824e6effec3e7212d4ca9c21ae0b6077daf5a974"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
